import os
import subprocess
from pyspark.sql import SparkSession
from modules.extract import load_imdb_dataset
from modules.transform import (
    dataset_info, numeric_stats,
    business_queries, join_examples,
    window_examples, save_results
)

# üëá –í–∫–∞–∑—É—î–º–æ PySpark, –¥–µ —à—É–∫–∞—Ç–∏ Python
os.environ["PYSPARK_PYTHON"] = r"D:\Coding\Projects\BigVidob\.venv\Scripts\python.exe"
os.environ["PYSPARK_DRIVER_PYTHON"] = r"D:\Coding\Projects\BigVidob\.venv\Scripts\python.exe"

# üîß –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞
os.environ["JAVA_HOME"] = r"C:\Program Files\Eclipse Adoptium\jdk-21.0.8.9-hotspot"
os.environ["SPARK_HOME"] = r"C:\spark"
os.environ["HADOOP_HOME"] = r"C:\spark"
os.environ["PATH"] += os.pathsep + os.path.join(os.environ["SPARK_HOME"], "bin")
os.environ["PATH"] += os.pathsep + os.path.join(os.environ["JAVA_HOME"], "bin")

# üîç –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ Java
try:
    subprocess.run(["java", "-version"], check=True)
except Exception as e:
    print("‚ùå Java –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞:", e)
    exit(1)

# üöÄ Spark Session
spark = SparkSession.builder.appName("IMDB Spark Project").master("local[*]").getOrCreate()

# üìÇ –ó—á–∏—Ç—É–≤–∞–Ω–Ω—è
df = load_imdb_dataset(spark, r"D:\Coding\Projects\BigVidob\data\title.basics.tsv")

# üîπ –í–∏–∫–æ–Ω–∞–Ω–Ω—è –µ—Ç–∞–ø—ñ–≤
dataset_info(df)
numeric_stats(df)
business_queries(df)
join_examples(df)
window_examples(df)

# üíæ –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
save_results(df)

spark.stop()
